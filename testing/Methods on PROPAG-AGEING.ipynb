{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from multiprocessing import Process, Manager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def set_Data(data):\n",
    "#     ppg = pd.read_csv('./trans_processed_PPG_data.csv')\n",
    "#     # data.rename(columns={'Unnamed: 0':'Sentrix_position'}, inplace=True)\n",
    "#     ppg.set_index('ID_REF', inplace=True)\n",
    "#     ppg = data.transpose()\n",
    "\n",
    "\n",
    "#     encoder = LabelEncoder()\n",
    "#     label = encoder.fit_transform(ppmi['Category'])\n",
    "#     tr = ppg.drop(['Category'], axis=1)\n",
    "#     X = tr.values\n",
    "#     y = label\n",
    "\n",
    "# #     print(\"StratifiedSampling check\")\n",
    "# #     split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "# #     split.get_n_splits(X, y)\n",
    "\n",
    "# #     for train_index, test_index in split.split(X, y):\n",
    "# #         X_train, X_test = X[train_index], X[test_index]\n",
    "# #         y_train, data['y_test'] = y[train_index], y[test_index]\n",
    "\n",
    "# #     print(\"Oversampling check\")\n",
    "# #     oversampler = SMOTE(random_state=42)\n",
    "# #     X_train_sampled, data['y_train_sampled'] = oversampler.fit_resample(X_train, y_train)\n",
    "#     print(\"Scaling check\")\n",
    "#     scaler = StandardScaler()\n",
    "#     X_scaled = scaler.fit_transform(X)\n",
    "# #     data['X_train_scaled_1'] = X_scaled[:247].reshape((1, -1))\n",
    "# #     data['X_train_scaled_2'] = X_scaled[247:].reshape((1, -1))\n",
    "#     data['X_scaled'] = X_scaled\n",
    "#     data['y'] = y\n",
    "    \n",
    "#     print(\"Returning check\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('./trans_processed_PPG_data.csv')\n",
    "# # data.rename(columns={'Unnamed: 0':'Sentrix_position'}, inplace=True)\n",
    "# data.set_index('ID_REF', inplace=True)\n",
    "# ppg = data.transpose()\n",
    "# ppg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from umap.umap_ import UMAP\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evalfw\n",
    "import pipelines\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_ppg = np.load('../../datasets/preprocessed/npy_files/X_scaled_ppg.npy')\n",
    "y_ppg = np.load('../../datasets/preprocessed/npy_files/y_ppg.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'evalfw' from '/local/scratch/rz296/methyl-data-handling/testing/evalfw.py'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(pipelines)\n",
    "importlib.reload(evalfw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set clf and dr\n",
    "dr = \"fs\"\n",
    "clf = \"lr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = \"mkdir /local/scratch/rz296/methyl-data-handling/testing/logs/ppg/\"+dr+\"_\"+clf\n",
    "os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in saved models -> only the best model is saved\n",
    "path = \"/local/scratch/rz296/trained-ml-models/\"+clf+\"/\"\n",
    "model = joblib.load(path+dr+\"_\"+clf+\".joblib\")\n",
    "# model.set_params(clf__gpu_id=1)\n",
    "print(model)\n",
    "ppg_clf_dict = {\n",
    "    clf:{\n",
    "        dr+\"_\"+clf:{\n",
    "            0:model\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

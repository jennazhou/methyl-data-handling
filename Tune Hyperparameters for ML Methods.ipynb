{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rz296/miniconda3/envs/partII/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3051: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "ppmi = pd.read_csv('./trans_processed_PPMI_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppmi.rename(columns={'Unnamed: 0':'Sentrix_position'}, inplace=True)\n",
    "ppmi.set_index('Sentrix_position', inplace=True)\n",
    "ppmi = ppmi.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Classifier on original unreduced data without anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "label = encoder.fit_transform(ppmi['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(436, 747668)\n",
      "(436,)\n"
     ]
    }
   ],
   "source": [
    "tr = ppmi.drop(['Category'], axis=1)\n",
    "X = tr.values\n",
    "y = label\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: 348 TEST: 88\n",
      "(348, 747668) (348,) (88, 747668) (88,)\n"
     ]
    }
   ],
   "source": [
    "#Stratified sampling\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "split.get_n_splits(X, y)\n",
    "\n",
    "for train_index, test_index in split.split(X, y):\n",
    "    print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index))\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "####所有的test都只能apply transform，不能用fit_transform!!!\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune parameters for Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######Train model using X_train_scaled for regulariser and C value strength\n",
    "###L1 first\n",
    "C_options = [0.01, 0.1, 1, 1.5, 10, 100]\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'C': C_options,\n",
    "    }\n",
    "]\n",
    "\n",
    "lr =  LogisticRegression(max_iter=500, penalty='l1', C=0.01, solver='saga')\n",
    "\n",
    "grid = GridSearchCV(lr, param_grid=param_grid, scoring=\"accuracy\", cv=6, n_jobs=6)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "y_pred = lr.predict\n",
    "mean_scores = np.array(grid.cv_results_['mean_test_score'])\n",
    "print(mean_scores)\n",
    "print('Best estimator: ', grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######Train model using X_train_scaled for regulariser and C value strength\n",
    "###L2 now\n",
    "C_options = [0.01, 0.1, 1, 1.5, 10, 100]\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'C': C_options,\n",
    "    }\n",
    "]\n",
    "\n",
    "lr =  LogisticRegression(max_iter=500, penalty='l2',solver='saga')\n",
    "\n",
    "grid = GridSearchCV(lr, param_grid=param_grid, scoring=\"accuracy\", n_jobs=5)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "mean_scores = np.array(grid.cv_results_['mean_test_score'])\n",
    "print(mean_scores)\n",
    "print('Best estimator: ', grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With elasticnet\n",
    "l1_ratio = [0.2, 0.5, 0.8]\n",
    "param_grid = [\n",
    "    {\n",
    "        'l1_ratio': l1_ratio,\n",
    "    }\n",
    "]\n",
    "\n",
    "lr =  LogisticRegression(max_iter=500, penalty='elasticnet',solver='saga')\n",
    "\n",
    "grid = GridSearchCV(lr, param_grid=param_grid, scoring=\"accuracy\", n_jobs=5)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "mean_scores = np.array(grid.cv_results_['mean_test_score'])\n",
    "print(mean_scores)\n",
    "print('Best estimator: ', grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "- cross_val_score: used as an analysis tool to evaluate the results obtained by training strategy used before (i.e. the model may be applied entirely)\n",
    "- cross_val_predict: apply cross-validation to training and get predictions and use it for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "####SGDClassifier with rbf kernel mapping\n",
    "\n",
    "###Approx SVC, hence set penalty to be l2\n",
    "\n",
    "# C_options = [0.01, 1, 100]\n",
    "# kernels=['rbf', 'poly', 'linear', 'sigmoid']\n",
    "# feature_map = Nystroem(gamma=1, random_state=1,n_components=300)\n",
    "# svm = SGDClassifier(penalty='l2', loss='hinge', tol=0.1)\n",
    "# svm_kernel_approx = Pipeline([\n",
    "#     (\"feature_map\", feature_map),\n",
    "#     (\"svm\", svm)\n",
    "# ])\n",
    "\n",
    "# param_grid = [\n",
    "#     {\n",
    "#         'feature_map__kernel': kernels,\n",
    "#         'svm__alpha': C_options,\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# svm_kernel_approx.fit(X_train_scaled, y_train)\n",
    "# y_pred_svm_approx = svm_kernel_approx.predict(X_test_scaled) \n",
    "\n",
    "### Conclusion: SVM without regularisation has \n",
    "### worse performance than Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###SVC as svm\n",
    "###3 hypeparameters\n",
    "kernels = ['rbf', 'poly', 'linear', 'sigmoid']\n",
    "C_options=[0.01, 1, 1000]\n",
    "gamma=[1e-4, 0.01, 1, 1.5]\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'C': C_options,\n",
    "        'kernel': kernels,\n",
    "        'gamma':gamma,\n",
    "    }\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid=param_grid, scoring=\"accuracy\", n_jobs=3)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "mean_scores = np.array(grid.cv_results_['mean_test_score'])\n",
    "print(mean_scores)\n",
    "print('Best estimator: ', grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of SVM: 0.7159090909090909\n",
      "Accuracy score of SGDClassifier with kernel approx: 0.7045454545454546\n"
     ]
    }
   ],
   "source": [
    "# print(\"Accuracy score of SVM:\", accuracy_score(y_test, y_pred_svm))\n",
    "# print(\"Accuracy score of SGDClassifier with kernel approx:\", accuracy_score(y_test, y_pred_svm_approx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tune parameters for Dimensionality Reduction techniques + classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _1.1 PCA_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######PCA on PPMI#########\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = [50, 100, 150, 200, 250]\n",
    "C_options = [0.01, 0.1, 1, 1.5, 10, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 PCA+LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rz296/miniconda3/envs/partII/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/rz296/miniconda3/envs/partII/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/rz296/miniconda3/envs/partII/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/rz296/miniconda3/envs/partII/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/rz296/miniconda3/envs/partII/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/rz296/miniconda3/envs/partII/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65217391 0.66393375 0.53138716 0.49714286 0.52004141]\n",
      "{'pca__n_components': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rz296/miniconda3/envs/partII/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "### Tune n_components for PCA+Logistic Regression\n",
    "###L1\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('pca', PCA()),\n",
    "    ('clf', LogisticRegression(max_iter=500, penalty='l1'))\n",
    "])\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'pca__n_components': n_components\n",
    "        'clf__C': C_options\n",
    "    },\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, scoring=\"accuracy\")\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "# evaluation metric is accuray \n",
    "\n",
    "mean_scores = np.array(grid.cv_results_['mean_test_score'])\n",
    "print(mean_scores)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tune n_components for PCA+Logistic Regression\n",
    "###L2\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('pca', PCA()),\n",
    "    ('clf', LogisticRegression(max_iter=500, penalty='l2'))\n",
    "])\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'pca__n_components': n_components\n",
    "        'clf__C': C_options\n",
    "    },\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, scoring=\"accuracy\")\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "# evaluation metric is accuray \n",
    "\n",
    "mean_scores = np.array(grid.cv_results_['mean_test_score'])\n",
    "print(mean_scores)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 PCA+SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61797101 0.61490683 0.62062112 0.63813665 0.63233954]\n",
      "Best estimator:  {'pca__n_components': 200}\n"
     ]
    }
   ],
   "source": [
    "### Tune n_components for PCA+SVM\n",
    "\n",
    "n_components = [50, 100, 150, 200, 250]\n",
    "kernels = ['rbf', 'poly', 'linear', 'sigmoid']\n",
    "C_options=[0.01, 1, 1000]\n",
    "gamma=[1e-4, 0.01, 1, 1.5]\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('pca', PCA()),\n",
    "    ('clf', SVC())\n",
    "])\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'pca__n_components': n_components,\n",
    "        'clf__C': C_options,\n",
    "        'clf__kernel': kernels,\n",
    "        'clf__gamma':gamma,\n",
    "    },\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, scoring=\"accuracy\",n_jobs=3)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "# evaluation metric is accuray \n",
    "\n",
    "mean_scores = np.array(grid.cv_results_['mean_test_score'])\n",
    "print(mean_scores)\n",
    "print('Best estimator: ', grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-----------\n",
    "Conclusion so far:  \n",
    "Applying PCA technique reduces the accuracy of model when only running on PPMI dataset  \n",
    "\n",
    "-----------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _1.2 UMAP_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap.umap_ import UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning UMAP hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 UMAP+LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68968944 0.68968944 0.68964803 0.68389234 0.6810766 ]\n",
      "{'umap__n_components': 50}\n"
     ]
    }
   ],
   "source": [
    "### Tune n_components for UMAP+Logistic Regression\n",
    "###L1\n",
    "n_components = [50, 100, 150, 200, 250]\n",
    "C_options = [0.01, 0.1, 1, 1.5, 10, 100]\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('umap', UMAP()),\n",
    "    ('clf', LogisticRegression(max_iter=500, penalty='l1'))\n",
    "])\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'umap__n_components': n_components\n",
    "        'clf__C': C_options\n",
    "    },\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, scoring=\"accuracy\")\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "# evaluation metric is accuray \n",
    "\n",
    "mean_scores = np.array(grid.cv_results_['mean_test_score'])\n",
    "print(mean_scores)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tune n_components for UMAP+Logistic Regression\n",
    "###L2\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('umap', UMAP()),\n",
    "    ('clf', LogisticRegression(max_iter=500, penalty='l2'))\n",
    "])\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'umap__n_components': n_components\n",
    "        'clf__C': C_options\n",
    "    },\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, scoring=\"accuracy\")\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "# evaluation metric is accuray \n",
    "\n",
    "mean_scores = np.array(grid.cv_results_['mean_test_score'])\n",
    "print(mean_scores)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 UMAP+SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68674948 0.69540373 0.68679089 0.68968944 0.68964803]\n",
      "Best estimator:  {'umap__n_components': 100}\n"
     ]
    }
   ],
   "source": [
    "### Tune n_components for UMAP+SVM\n",
    "\n",
    "n_components = [50, 100, 150, 200, 250]\n",
    "kernels = ['rbf', 'poly', 'linear', 'sigmoid']\n",
    "C_options=[0.01, 1, 1000]\n",
    "gamma=[1e-4, 0.01, 1, 1.5]\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('umap', UMAP()),\n",
    "    ('clf', SVC())\n",
    "])\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'umap__n_components': n_components,\n",
    "        'clf__C': C_options,\n",
    "        'clf__kernel': kernels,\n",
    "        'clf__gamma':gamma,\n",
    "    },\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, scoring=\"accuracy\",n_jobs=3)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "# evaluation metric is accuray \n",
    "\n",
    "mean_scores = np.array(grid.cv_results_['mean_test_score'])\n",
    "print(mean_scores)\n",
    "print('Best estimator: ', grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 ICA and Tune hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FastICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rz296/miniconda3/envs/partII/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/rz296/miniconda3/envs/partII/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/rz296/miniconda3/envs/partII/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/rz296/miniconda3/envs/partII/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/rz296/miniconda3/envs/partII/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67817805 0.62927536 0.64057971 0.61494824 0.65229814]\n"
     ]
    }
   ],
   "source": [
    "### Tune n_components for ICA+Logistic Regression\n",
    "###L1\n",
    "n_components = [50, 100, 150, 200, 250]\n",
    "C_options = [0.01, 0.1, 1, 1.5, 10, 100]\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('ica', FastICA()),\n",
    "    ('clf', LogisticRegression(max_iter=500, penalty='l1'))\n",
    "])\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'ica__n_components': n_components\n",
    "        'clf__C': C_options\n",
    "    },\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, scoring=\"accuracy\")\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "# evaluation metric is accuray \n",
    "\n",
    "mean_scores = np.array(grid.cv_results_['mean_test_score'])\n",
    "print(mean_scores)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tune n_components for ICA+Logistic Regression\n",
    "###L2\n",
    "n_components = [50, 100, 150, 200, 250]\n",
    "C_options = [0.01, 0.1, 1, 1.5, 10, 100]\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('ica', FastICA()),\n",
    "    ('clf', LogisticRegression(max_iter=500, penalty='l2'))\n",
    "])\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'ica__n_components': n_components\n",
    "        'clf__C': C_options\n",
    "    },\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, scoring=\"accuracy\")\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "# evaluation metric is accuray \n",
    "\n",
    "mean_scores = np.array(grid.cv_results_['mean_test_score'])\n",
    "print(mean_scores)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62662526 0.62658385 0.62650104 0.58339545 0.63817805]\n",
      "Best estimator:  {'ica__n_components': 250}\n"
     ]
    }
   ],
   "source": [
    "### Tune n_components for ICA+SVM\n",
    "\n",
    "n_components = [50, 100, 150, 200, 250]\n",
    "kernels = ['rbf', 'poly', 'linear', 'sigmoid']\n",
    "C_options=[0.01, 1, 1000]\n",
    "gamma=[1e-4, 0.01, 1, 1.5]\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('umap', UMAP()),\n",
    "    ('clf', SVC())\n",
    "])\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'umap__n_components': n_components,\n",
    "        'clf__C': C_options,\n",
    "        'clf__kernel': kernels,\n",
    "        'clf__gamma':gamma,\n",
    "    },\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, scoring=\"accuracy\",n_jobs=3)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "# evaluation metric is accuray \n",
    "\n",
    "mean_scores = np.array(grid.cv_results_['mean_test_score'])\n",
    "print(mean_scores)\n",
    "print('Best estimator: ', grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Regularisation to FS for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Use regularisation as Feature Selection technique to \n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####this returns the values that are positive after regularisation \n",
    "#Try different C value\n",
    "sel_ = SelectFromModel(LogisticRegression(C=1, penalty='l1'))\n",
    "sel_.fit(X_train_scaled, y_train)\n",
    "#### sel_.get_support() returns a boolean matrix where True indicates the entries bigger than 0 and False otherwise\n",
    "# selected_feat = X_train.columns[(sel_.get_support())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Transform the original data to only the selected features based on regulariser\n",
    "X_train_selected = sel_.transform(X_train_scaled)\n",
    "X_test_selected = sel_.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tune C value for regulariser for FS, then LR\n",
    "###L1\n",
    "C_options=[0.01, 1, 1000]\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('sel', SelectFromModel(LogisticRegression(C=1, penalty='l1'))),\n",
    "    ('clf', LogisticRegression(max_iter=500, penalty='l2'))\n",
    "])\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'sel__estimator__C': C_options #??\n",
    "        'clf__C': C_options\n",
    "    },\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, scoring=\"accuracy\")\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "# evaluation metric is accuray \n",
    "\n",
    "mean_scores = np.array(grid.cv_results_['mean_test_score'])\n",
    "print(mean_scores)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tune C value for regulariser for FS, then LR\n",
    "###L2\n",
    "C_options=[0.01, 1, 1000]\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('sel', SelectFromModel(LogisticRegression(C=1, penalty='l2'))),\n",
    "    ('clf', LogisticRegression(max_iter=500, penalty='l2'))\n",
    "])\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'sel__estimator__C': C_options, #??\n",
    "        'clf__C': C_options\n",
    "    },\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, scoring=\"accuracy\")\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "# evaluation metric is accuray \n",
    "\n",
    "mean_scores = np.array(grid.cv_results_['mean_test_score'])\n",
    "print(mean_scores)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tune C value for regulariser for FS, then SVM\n",
    "\n",
    "C_options=[0.01, 1, 1000]\n",
    "kernels = ['rbf', 'poly']\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('sel', SelectFromModel(LogisticRegression(C=1, penalty='l1'))),\n",
    "    ('clf', SVC(max_iter=500))\n",
    "])\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'sel__estimator__C': C_options, #??\n",
    "        'clf__C': C_options,\n",
    "        'clf__kernel': kernels\n",
    "    },\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, scoring=\"accuracy\")\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "# evaluation metric is accuray \n",
    "\n",
    "mean_scores = np.array(grid.cv_results_['mean_test_score'])\n",
    "print(mean_scores)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 3. VAE DR + CLF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow_core._api.v2.config' has no attribute 'experimental_list_devices'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3d00d838479b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_available_gpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/partII/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_get_available_gpus\u001b[0;34m()\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0m_LOCAL_DEVICES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m             \u001b[0m_LOCAL_DEVICES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_list_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_LOCAL_DEVICES\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'device:gpu'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow_core._api.v2.config' has no attribute 'experimental_list_devices'"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
